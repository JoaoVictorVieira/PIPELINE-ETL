{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silver Layer - Limpeza e Normalização",
    "# Objetivo: Limpar e normalizar os dados da camada Bronze, criando tabelas dimensionais e fatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas"
     ]
    }
   ],
   "source": [
    "import sys",
    "import os",
    "sys.path.append(os.path.abspath('../src'))",
    "",
    "import pandas as pd",
    "import numpy as np",
    "from pyspark.sql import SparkSession",
    "from pyspark.sql import functions as F",
    "from pyspark.sql.window import Window",
    "from sqlalchemy import create_engine, text",
    "import warnings",
    "warnings.filterwarnings('ignore')",
    "",
    "print(\" Bibliotecas importadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found",
      "Setting default log level to \"WARN\".",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).",
      "25/10/16 20:21:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 3.5.1"
     ]
    }
   ],
   "source": [
    "# Spark",
    "spark = SparkSession.builder \\",
    ".appName(\"Silver_Layer_Censo_2022\") \\",
    ".config(\"spark.driver.memory\", \"4g\") \\",
    ".getOrCreate()",
    "",
    "print(f\" Spark {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL configurado"
     ]
    }
   ],
   "source": [
    "",
    "POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'localhost')",
    "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '5432')",
    "POSTGRES_DB = os.getenv('POSTGRES_DB', 'etl_censo')",
    "POSTGRES_USER = os.getenv('POSTGRES_USER', 'etl_user')",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD', 'etl_password')",
    "",
    "postgres_url = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"",
    "engine = create_engine(postgres_url, pool_pre_ping=True)",
    "",
    "jdbc_url = f\"jdbc:postgresql://{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"",
    "connection_properties = {",
    "\"user\": POSTGRES_USER,",
    "\"password\": POSTGRES_PASSWORD,",
    "\"driver\": \"org.postgresql.Driver\"",
    "}",
    "",
    "print(\" PostgreSQL configurado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Criar Dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Limpando dependências...",
      "silver.fato_trabalho removida",
      "silver.dim_uf removida",
      "silver.dim_sexo removida",
      "silver.dim_cor_raca removida",
      "silver.dim_nivel_instrucao removida",
      "Dependências limpas"
     ]
    }
   ],
   "source": [
    "# Limpar dependências antes de recriar tabelas",
    "print(\"🧹 Limpando dependências...\")",
    "with engine.connect() as conn:",
    "# Desabilitar verificações de chave estrangeira temporariamente",
    "conn.execute(text(\"SET session_replication_role = replica;\"))",
    "",
    "# Dropar tabelas com dependências",
    "try:",
    "conn.execute(text(\"DROP TABLE IF EXISTS silver.fato_trabalho CASCADE;\"))",
    "print(\" silver.fato_trabalho removida\")",
    "except:",
    "pass",
    "",
    "try:",
    "conn.execute(text(\"DROP TABLE IF EXISTS silver.dim_uf CASCADE;\"))",
    "print(\" silver.dim_uf removida\")",
    "except:",
    "pass",
    "",
    "try:",
    "conn.execute(text(\"DROP TABLE IF EXISTS silver.dim_sexo CASCADE;\"))",
    "print(\" silver.dim_sexo removida\")",
    "except:",
    "pass",
    "",
    "try:",
    "conn.execute(text(\"DROP TABLE IF EXISTS silver.dim_cor_raca CASCADE;\"))",
    "print(\" silver.dim_cor_raca removida\")",
    "except:",
    "pass",
    "",
    "try:",
    "conn.execute(text(\"DROP TABLE IF EXISTS silver.dim_nivel_instrucao CASCADE;\"))",
    "print(\" silver.dim_nivel_instrucao removida\")",
    "except:",
    "pass",
    "",
    "# Reabilitar verificações de chave estrangeira",
    "conn.execute(text(\"SET session_replication_role = DEFAULT;\"))",
    "conn.commit()",
    "",
    "print(\" Dependências limpas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Dimensão UF/Região"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.dim_uf: 27 UFs"
     ]
    }
   ],
   "source": [
    "dim_uf_data = [",
    "('AC','N','Acre'),('AM','N','Amazonas'),('AP','N','Amapá'),('PA','N','Pará'),",
    "('RO','N','Rondônia'),('RR','N','Roraima'),('TO','N','Tocantins'),",
    "('AL','NE','Alagoas'),('BA','NE','Bahia'),('CE','NE','Ceará'),('MA','NE','Maranhão'),",
    "('PB','NE','Paraíba'),('PE','NE','Pernambuco'),('PI','NE','Piauí'),",
    "('RN','NE','Rio Grande do Norte'),('SE','NE','Sergipe'),",
    "('ES','SE','Espírito Santo'),('MG','SE','Minas Gerais'),",
    "('RJ','SE','Rio de Janeiro'),('SP','SE','São Paulo'),",
    "('PR','S','Paraná'),('RS','S','Rio Grande do Sul'),('SC','S','Santa Catarina'),",
    "('DF','CO','Distrito Federal'),('GO','CO','Goiás'),",
    "('MS','CO','Mato Grosso do Sul'),('MT','CO','Mato Grosso')",
    "]",
    "",
    "dim_uf = pd.DataFrame(dim_uf_data, columns=['uf', 'regiao', 'nome_uf'])",
    "dim_uf.to_sql('dim_uf', engine, schema='silver', if_exists='replace', index=False)",
    "print(f\" silver.dim_uf: {len(dim_uf)} UFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Dimensão Sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.dim_sexo: 2 categorias"
     ]
    }
   ],
   "source": [
    "dim_sexo_data = [",
    "('M', 'Masculino'),",
    "('F', 'Feminino')",
    "]",
    "",
    "dim_sexo = pd.DataFrame(dim_sexo_data, columns=['sexo_codigo', 'sexo_descricao'])",
    "dim_sexo.to_sql('dim_sexo', engine, schema='silver', if_exists='replace', index=False)",
    "print(f\" silver.dim_sexo: {len(dim_sexo)} categorias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Dimensão Cor/Raça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.dim_cor_raca: 5 categorias"
     ]
    }
   ],
   "source": [
    "dim_cor_raca_data = [",
    "('B', 'Branca'),",
    "('P', 'Parda'),",
    "('N', 'Preta'),",
    "('A', 'Amarela'),",
    "('I', 'Indígena')",
    "]",
    "",
    "dim_cor_raca = pd.DataFrame(dim_cor_raca_data, columns=['cor_raca_codigo', 'cor_raca_descricao'])",
    "dim_cor_raca.to_sql('dim_cor_raca', engine, schema='silver', if_exists='replace', index=False)",
    "print(f\" silver.dim_cor_raca: {len(dim_cor_raca)} categorias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Dimensão Nível de Instrução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.dim_nivel_instrucao: 8 níveis"
     ]
    }
   ],
   "source": [
    "dim_nivel_data = [",
    "('0', 'Sem instrução'),",
    "('1', 'Fundamental incompleto'),",
    "('2', 'Fundamental completo'),",
    "('3', 'Médio incompleto'),",
    "('4', 'Médio completo'),",
    "('5', 'Superior incompleto'),",
    "('6', 'Superior completo'),",
    "('7', 'Pós-graduação')",
    "]",
    "",
    "dim_nivel = pd.DataFrame(dim_nivel_data, columns=['nivel_codigo', 'nivel_descricao'])",
    "dim_nivel.to_sql('dim_nivel_instrucao', engine, schema='silver', if_exists='replace', index=False)",
    "print(f\" silver.dim_nivel_instrucao: {len(dim_nivel)} níveis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Criar Fatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Fato Trabalho/Rendimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.fato_trabalho: 1,350 registros"
     ]
    }
   ],
   "source": [
    "# Ler dados de rendimento do Bronze",
    "df_trab = pd.read_sql(\"SELECT * FROM bronze.censo_trabalhadores\", engine)",
    "",
    "# Validar e limpar",
    "df_trab = df_trab.dropna(subset=['uf', 'rendimento_mensal_nominal', 'populacao_ocupada'])",
    "df_trab = df_trab[df_trab['populacao_ocupada'] > 0]",
    "df_trab = df_trab[df_trab['rendimento_mensal_nominal'] >= 0]",
    "",
    "# Salvar na camada Silver",
    "df_trab.to_sql('fato_trabalho', engine, schema='silver', if_exists='replace', index=False)",
    "print(f\" silver.fato_trabalho: {len(df_trab):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Fato Crescimento Populacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.fato_crescimento_populacional: 13 registros"
     ]
    }
   ],
   "source": [
    "# Ler crescimento populacional do Bronze",
    "df_cresc = pd.read_sql(\"SELECT * FROM bronze.crescimento_populacional\", engine)",
    "",
    "# Calcular crescimento anual e taxa",
    "df_cresc = df_cresc.sort_values('ano_pesquisa')",
    "df_cresc['crescimento_anual'] = df_cresc['populacao_pessoas'].diff()",
    "df_cresc['taxa_crescimento'] = (df_cresc['crescimento_anual'] / df_cresc['populacao_pessoas'].shift(1) * 100).round(2)",
    "",
    "# Salvar na camada Silver",
    "df_cresc.to_sql('fato_crescimento_populacional', engine, schema='silver', if_exists='replace', index=False)",
    "print(f\" silver.fato_crescimento_populacional: {len(df_cresc)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Fato Território"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.fato_territorio: 1 registros"
     ]
    }
   ],
   "source": [
    "# Ler território do Bronze",
    "df_terr = pd.read_sql(\"SELECT * FROM bronze.territorio\", engine)",
    "",
    "# Salvar na camada Silver",
    "df_terr.to_sql('fato_territorio', engine, schema='silver', if_exists='replace', index=False)",
    "print(f\" silver.fato_territorio: {len(df_terr)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Fato Características do Domicílio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.fato_caracteristicas_domicilio: 4 registros"
     ]
    }
   ],
   "source": [
    "# Ler características dos domicílios do Bronze",
    "df_carac = pd.read_sql(\"SELECT * FROM bronze.caracteristicas_domicilios\", engine)",
    "",
    "# Salvar na camada Silver",
    "df_carac.to_sql('fato_caracteristicas_domicilio', engine, schema='silver', if_exists='replace', index=False)",
    "print(f\" silver.fato_caracteristicas_domicilio: {len(df_carac)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "",
      "======================================================================",
      "Resumo da camada SILVER",
      "======================================================================",
      "Tabela Registros",
      "----------------------------------------------------------------------",
      "dim_cor_raca 5 (DIM)",
      "dim_nivel_instrucao 8 (DIM)",
      "dim_sexo 2 (DIM)",
      "dim_uf 27 (DIM)",
      "fato_caracteristicas_domicilio 4 (FATO)",
      "fato_crescimento_populacional 13 (FATO)",
      "fato_territorio 1 (FATO)",
      "fato_trabalho 1,350 (FATO)",
      "----------------------------------------------------------------------",
      "TOTAL 1,410",
      "======================================================================"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:",
    "result = conn.execute(text(\"\"\"",
    "SELECT table_name FROM information_schema.tables",
    "WHERE table_schema = 'silver' ORDER BY table_name",
    "\"\"\"))",
    "",
    "print(\"\\n\" + \"=\"*70)",
    "print(\" Resumo da camada SILVER\")",
    "print(\"=\"*70)",
    "print(f\"{'Tabela':<40} {'Registros':>15}\")",
    "print(\"-\"*70)",
    "",
    "total_reg = 0",
    "for row in result:",
    "count_result = conn.execute(text(f\"SELECT COUNT(*) FROM silver.{row[0]}\"))",
    "count = count_result.fetchone()[0]",
    "tipo = \"DIM\" if row[0].startswith('dim_') else \"FATO\"",
    "print(f\"{row[0]:<40} {count:>15,} ({tipo})\")",
    "total_reg += count",
    "",
    "print(\"-\"*70)",
    "print(f\"{'TOTAL':<40} {total_reg:>15,}\")",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "",
      "======================================================================",
      "SILVER LAYER CONCLUÍDA concluída",
      "======================================================================",
      "",
      "Estrutura criada:",
      "",
      "DIMENSÕES:",
      "dim_uf (27 UFs + regiões)",
      "dim_sexo (2 categorias)",
      "dim_cor_raca (5 categorias)",
      "dim_nivel_instrucao (8 níveis)",
      "",
      "FATOS:",
      "fato_trabalho (rendimento por UF/sexo/raça)",
      "fato_crescimento_populacional (histórico 1872-2022)",
      "fato_territorio (área e densidade)",
      "fato_caracteristicas_domicilio (saneamento, infraestrutura)",
      "",
      "Próximo passo: Executar gold.ipynb para calcular indicadores"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)",
    "print(\" SILVER LAYER CONCLUÍDA concluída\")",
    "print(\"=\"*70)",
    "print(\"\\n Estrutura criada:\")",
    "print(\"\\n DIMENSÕES:\")",
    "print(\" dim_uf (27 UFs + regiões)\")",
    "print(\" dim_sexo (2 categorias)\")",
    "print(\" dim_cor_raca (5 categorias)\")",
    "print(\" dim_nivel_instrucao (8 níveis)\")",
    "print(\"\\n FATOS:\")",
    "print(\" fato_trabalho (rendimento por UF/sexo/raça)\")",
    "print(\" fato_crescimento_populacional (histórico 1872-2022)\")",
    "print(\" fato_territorio (área e densidade)\")",
    "print(\" fato_caracteristicas_domicilio (saneamento, infraestrutura)\")",
    "print(\"\\n Próximo passo: Executar gold.ipynb para calcular indicadores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session encerrada"
     ]
    }
   ],
   "source": [
    "spark.stop()",
    "print(\" Spark Session encerrada\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}